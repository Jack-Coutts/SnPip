{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1355884-a72e-422f-82f3-be5585d56cd8",
   "metadata": {},
   "source": [
    "## Genotype information encoder\n",
    "\n",
    "**Input:** A gzipped VCF file containing all SNPs for all populations. An CSV/TSV file mapping the subpopulations/populations to the sample names.\n",
    "\n",
    "**Output:** A CSV file containing the encoded genotype information sequence for each SNP. This encoded sequence contains the genotype info for all samples/populations for the SNP in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "799cbef7-cf2e-4677-a576-677499bb79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create initial encoder which converts geneotype info into a character string and produces and\n",
    "   order dictionary for the sequence. These are outputted as two CSV files. '''\n",
    "\n",
    "def encoderseq(infile, outdb, outorder):\n",
    "    \n",
    "    # import modules needed for function\n",
    "    import csv\n",
    "    import gzip\n",
    "    import time\n",
    "\n",
    "    # dictionary for translating genotype info\n",
    "    ginfo={'1|0':'a', '1|1':'b', '0|1':'c','0|0':'d'}\n",
    "\n",
    "    #Time how long it takes to run\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Open gzipped file \n",
    "    with gzip.open(infile,'rt') as vcf:\n",
    "\n",
    "        # Create empty dictionary that will be populated with rsIDs and genptype frequencies\n",
    "        dictionary={}\n",
    "        \n",
    "        # create empty dictionary for order of samples\n",
    "        order={}\n",
    "\n",
    "        # Iterate over each line in a VCF\n",
    "        for line in vcf:\n",
    "            \n",
    "            # create empty string to input genotype info\n",
    "            string=''\n",
    "\n",
    "            # Ignore info lines\n",
    "            if line.strip().startswith(\"##\"):\n",
    "                pass\n",
    "\n",
    "            # column heading line\n",
    "            elif line.strip().startswith(\"#\"):\n",
    "                \n",
    "                # Seperate each line into a list of seperate elements \n",
    "                items=line.split('\\t')\n",
    "                \n",
    "                # Start a counter that will as order\n",
    "                counter=0\n",
    "                \n",
    "                # Select only samples \n",
    "                for item in items:\n",
    "                    \n",
    "                    item = item.strip('\\n').strip('\\t')\n",
    "                    \n",
    "                    if item == '#CHROM':\n",
    "                        pass\n",
    "                    elif item == 'POS':\n",
    "                        pass\n",
    "                    elif item == 'ID':\n",
    "                        pass\n",
    "                    elif item == 'REF':\n",
    "                        pass\n",
    "                    elif item == 'ALT':\n",
    "                        pass\n",
    "                    elif item == 'QUAL':\n",
    "                        pass\n",
    "                    elif item == 'FILTER':\n",
    "                        pass\n",
    "                    elif item == 'INFO':\n",
    "                        pass\n",
    "                    elif item == 'FORMAT':\n",
    "                        pass\n",
    "                    else:\n",
    "                        \n",
    "                        #Add sample to dictionary as the key\n",
    "                        sample = item\n",
    "                        #Add counter & sample to dictionary\n",
    "                        order[sample] = str(counter)\n",
    "                        counter+=1\n",
    "\n",
    "            # If not an info line\n",
    "            else:\n",
    "            \n",
    "                # Seperate each line into a list of seperate elements \n",
    "                items=line.split('\\t')\n",
    "\n",
    "                # Iterate over items in list (the line)\n",
    "                for item in items:\n",
    "                    \n",
    "                    item=item.strip('\\n').strip('\\t')\n",
    "\n",
    "                    # Select the line rsID\n",
    "                    if item.startswith('rs',0) == True:\n",
    "\n",
    "                        #Add rsID to dictionary as the key\n",
    "                        rsID = item\n",
    "                        dictionary[rsID] = []\n",
    "\n",
    "\n",
    "                    # Select the genotype columns\n",
    "                    elif item.startswith('1|',0) == True or item.startswith('0|',0)== True:\n",
    "\n",
    "                        # Add to the genotype counters\n",
    "                        # Using starts with rather than == because the final entry ends with \\n\n",
    "                        if item.startswith('1|0',0) == True:\n",
    "                            string+=ginfo[item]\n",
    "\n",
    "                        elif item.startswith('0|1',0) == True:\n",
    "                            string+=ginfo[item]\n",
    "\n",
    "                        elif item.startswith('1|1',0) == True:\n",
    "                            string+=ginfo[item]\n",
    "\n",
    "                        elif item.startswith('0|0',0) == True:\n",
    "                            string+=ginfo[item]\n",
    "                            \n",
    "                        else:                            \n",
    "                            string+='-'\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                # Add the geneotype list as the dictionary value            \n",
    "                dictionary[rsID]=string \n",
    "\n",
    "    # Write the seq dictionary as a csv file\n",
    "    with open(outdb, 'w') as f:\n",
    "        for key in dictionary.keys():\n",
    "            f.write(\"%s, %s\\n\" % (key, dictionary[key]))\n",
    "            \n",
    "    # Write the order dictionary as a csv file\n",
    "    with open(outorder, 'w') as p:\n",
    "        for key in order.keys():\n",
    "            p.write(\"%s, %s\\n\" % (key, order[key]))\n",
    "\n",
    "    print(\"Files created in --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1de22578-fa87-4994-a4cd-799b5cef6fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files created in --- 595.3310840129852 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Write initial encoded sequences and order file\n",
    "encoderseq('anno_biallelic_ALL_5.vcf.gz', 'dbseq.csv', 'sorder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3723679b-7453-4bfb-8691-d198b058777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Check that all of the samples in the order file (taken straight from the VCF) are in the index file, \n",
    "    if not, add them and manually search their subpopulation'''\n",
    "\n",
    "def checkfiles(index_file, order_file, output_file):\n",
    "    \n",
    "    import csv\n",
    "    import time\n",
    "    \n",
    "    #Time how long it takes to run\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # csv file will be converted into this dictionary \n",
    "    order={}\n",
    "    with open(order_file,'r') as inp:\n",
    "        reader = csv.reader(inp)\n",
    "        order= {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "    # csv file will be converted into this dictionary\n",
    "    index={}\n",
    "    \n",
    "    with open(index_file,'r') as inp:\n",
    "        next(inp)\n",
    "        reader = csv.reader(inp, delimiter = '\\t')#tsv file\n",
    "        index= {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "    # Create lists of the keys in each dictionary - these are the samples\n",
    "    orderkeys= order.keys()\n",
    "    indexkeys= index.keys()\n",
    "    \n",
    "    # Determine whether there are any keys missing in the index\n",
    "    differences = list(set(orderkeys) - set(indexkeys))# These are all peruvian - I checked on 1000 genome browser\n",
    "    \n",
    "    # After checking the population of the missing keys, add them to index\n",
    "    for item in differences:\n",
    "        \n",
    "        index[item]='PEL'\n",
    "    \n",
    "    # Write the index dictionary as a csv file\n",
    "    with open(output_file, 'w') as f:\n",
    "        for key in index.keys():\n",
    "            f.write(\"%s, %s\\n\" % (key, index[key]))\n",
    "\n",
    "\n",
    "    print(\"File created in --- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    return differences \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d6b9e4f-ca8a-473e-a521-7aaf30f7c93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created in --- 0.0035381317138671875 seconds ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['HG01565', 'HG01572', 'HG01566', 'HG01577', 'HG01578', 'HG01571']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkfiles('panel_index.csv', 'sorder.csv', 'sample_index.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fa1bf5a2-4ecd-49ed-9c41-8f8431abaf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of order from csv order file - used in second stage of encoding\n",
    "\n",
    "def dictorder(file):\n",
    "    \n",
    "    import csv\n",
    "    \n",
    "    index={}\n",
    "    with open(file,'r') as inp:\n",
    "        reader = csv.reader(inp)\n",
    "        index= {int(rows[1]):rows[0] for rows in reader}\n",
    "    \n",
    "    \n",
    "    return index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cd089bd1-751f-42e0-8fe8-470bc0d4d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of sample-subpopulations - used in second stage of encoding\n",
    "\n",
    "def dictsubpop(file):\n",
    "    \n",
    "    import csv\n",
    "    \n",
    "    index={}\n",
    "    with open(file,'r') as inp:\n",
    "        reader = csv.reader(inp,)\n",
    "        index= {rows[0]:rows[1] for rows in reader}\n",
    "    \n",
    "    \n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "039ed0c2-cdac-486e-910f-8bcc5693becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fully encoded rsID-sequence file\n",
    "\n",
    "def encoded(order_file, index_file, sequence_file, output_file):\n",
    "    \n",
    "    # dictionaries of subpop-based encoding\n",
    "    nested_dictionary= {'GBR' :{'a':'e','b':'f','c':'g','d':'h'},\n",
    "                        'PEL' :{'a':'i','b':'j','c':'k','d':'l'},\n",
    "                        'ESN' :{'a':'m','b':'n','c':'o','d':'p'},\n",
    "                        'BEB' :{'a':'q','b':'r','c':'s','d':'t'},\n",
    "                        'CHB' :{'a':'u','b':'v','c':'w','d':'x'}}\n",
    "    \n",
    "    import csv\n",
    "    import time\n",
    "    \n",
    "    #Time how long it takes to run\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create dictionaries from the order and index files\n",
    "    order=dictorder(order_file)\n",
    "    index=dictsubpop(index_file)\n",
    "    \n",
    "    # Empty dictionary which will be the output file\n",
    "    output_dict={}\n",
    "    \n",
    "    # open the initial encoding csv file\n",
    "    with open(sequence_file, 'rt') as f:\n",
    "        \n",
    "        # for row in csv\n",
    "        for line in f:\n",
    "            \n",
    "            # create a list containing rsID and initial sequence\n",
    "            line = line.split(',')\n",
    "            \n",
    "            # This will be the encoded sequence\n",
    "            new_seq=''\n",
    "            \n",
    "            for item in line:\n",
    "                \n",
    "                item = item.strip('\\n').strip('\\t').strip(' ')\n",
    "                \n",
    "                # extract rsID as dictionary key\n",
    "                if item.startswith('rs') == True:\n",
    "                \n",
    "                    ID=item\n",
    "                    output_dict[ID]=''\n",
    "                    \n",
    "                else: # if not rsID then it is the sequence\n",
    "                    # counter to search dictionaries\n",
    "                    count = 0\n",
    "                    \n",
    "                    for character in item:\n",
    "                        # use counter to search sample name\n",
    "                        p=order[count]\n",
    "                        # use sample name to search subpop\n",
    "                        subpop=index[p].strip(' ')\n",
    "                        # use subpop and character to seach encoded charcter\n",
    "                        letter=nested_dictionary[subpop][character]\n",
    "                        # add encoded character to sequence\n",
    "                        new_seq+=letter\n",
    "                        # increase count to seach the next sample\n",
    "                        count+=1\n",
    "            # Add sequence as value to dictionary\n",
    "            output_dict[ID]=new_seq\n",
    "        \n",
    "        # Write the encoded seq dictionary as a csv file\n",
    "        with open(output_file, 'w') as f:\n",
    "            for key in output_dict.keys():\n",
    "                f.write(\"%s, %s\\n\" % (key, output_dict[key]))\n",
    "\n",
    "\n",
    "        print(\"File created in --- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6c33da8e-4b0b-4a8c-bf24-317e023846b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File created in --- 119.58313822746277 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# create encoded sequence file\n",
    "encoded('sorder.csv', 'sample_index.csv','dbseq.csv', 'encoded.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
